{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(data)\n",
      "datasets = data.load_data()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Extracting features for UVA\n",
        "-- missing 2/1010 feature values for Volume\n",
        "-- missing 1/1010 feature values for Embo\n",
        "Sex                            int64\n",
        "Age                          float64\n",
        "SM_Vein                        int64\n",
        "Diameter                     float64\n",
        "Volume                       float64\n",
        "History_of_Hemorrhage          int64\n",
        "Embo                         float64\n",
        "Aneurysm                     float64\n",
        "Max_Dose                     float64\n",
        "Marginal_Dose                float64\n",
        "Isodose                      float64\n",
        "Shots                        float64\n",
        "Surgery                         bool\n",
        "Location_frontal                bool\n",
        "Location_2                      bool\n",
        "Location_3                      bool\n",
        "Location_4                      bool\n",
        "Location_5                      bool\n",
        "Location_6                      bool\n",
        "Location_7                      bool\n",
        "Location_8                      bool\n",
        "Location_9                      bool\n",
        "Max_Dose_over_Volume         float64\n",
        "Isodose_over_Volume          float64\n",
        "Marginal_Dose_over_Volume    float64\n",
        "dtype: object\n",
        "-- Row-wise feature mask len=1010, type=<type 'numpy.ndarray'>, dtype=bool, sum=1007\n",
        "# censored at 4.000000 years: 100 / 1010\n",
        "-- Followup mask len=1010, type=<type 'numpy.ndarray'>, dtype=bool, sum=910\n",
        "-- Total patients=1010, Complete patient rows=1007, Patients with sufficient followup=910, Dataset size=907\n",
        "X (907, 25) float64\n",
        "Y (907,) bool\n",
        "Extracting features for PA\n",
        "-- missing 2/800 feature values for Aneurysm\n",
        "-- missing 7/800 feature values for Shots\n",
        "Sex                            int64\n",
        "Age                          float64\n",
        "SM_Vein                        int64\n",
        "Diameter                     float64\n",
        "Volume                       float64\n",
        "History_of_Hemorrhage          int64\n",
        "Embo                         float64\n",
        "Aneurysm                     float64\n",
        "Max_Dose                     float64\n",
        "Marginal_Dose                float64\n",
        "Isodose                      float64\n",
        "Shots                        float64\n",
        "Surgery                         bool\n",
        "Location_frontal                bool\n",
        "Location_2                      bool\n",
        "Location_3                      bool\n",
        "Location_4                      bool\n",
        "Location_5                      bool\n",
        "Location_6                      bool\n",
        "Location_7                      bool\n",
        "Location_8                      bool\n",
        "Location_9                      bool\n",
        "Max_Dose_over_Volume         float64\n",
        "Isodose_over_Volume          float64\n",
        "Marginal_Dose_over_Volume    float64\n",
        "dtype: object\n",
        "-- Row-wise feature mask len=800, type=<type 'numpy.ndarray'>, dtype=bool, sum=793\n",
        "# censored at 4.000000 years: 259 / 800\n",
        "-- Followup mask len=800, type=<type 'numpy.ndarray'>, dtype=bool, sum=541\n",
        "-- Total patients=800, Complete patient rows=793, Patients with sufficient followup=541, Dataset size=535\n",
        "X (535, 25) float64\n",
        "Y (535,) bool\n"
       ]
      }
     ],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datasets['pa'][0].sum(axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 125,
       "text": [
        "array([   796.        ,   2627.49392074,    306.        ,  11794.7       ,\n",
        "         2079.9898    ,    285.        ,     71.        ,     62.        ,\n",
        "        20875.84      ,  11184.9       ,  29108.        ,   1714.        ,\n",
        "           56.        ,    108.        ,     80.        ,     89.        ,\n",
        "           56.        ,     50.        ,     45.        ,     33.        ,\n",
        "           34.        ,     40.        ,  16732.59750332,  24009.31999753,\n",
        "         9360.18622551])"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "candidate_models = {}\n",
      "Cs = [10.0 ** -6, 10.0 ** -5, 0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]\n",
      "lr_parameter_grids = [\n",
      "    {\n",
      "         'penalty' : ['l1', 'l2'],\n",
      "         'fit_intercept' : [True, False],\n",
      "         'C' : Cs, \n",
      "    }\n",
      "]\n",
      "lr = sklearn.linear_model.LogisticRegression()\n",
      "candidate_models[lr] = lr_parameter_grids\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_uva, Y_uva = datasets['uva']\n",
      "X_pa, Y_pa = datasets['pa']\n",
      "\n",
      "X_combined = np.vstack([X_uva, X_pa])\n",
      "Y_combined = np.hstack([Y_uva, Y_pa])\n",
      "\n",
      "assert len(X_combined) == len(Y_combined)\n",
      "n_combined = len(X_combined)\n",
      "mask = np.random.randn(n_combined) > 0\n",
      "\n",
      "X_train = X_combined[mask]\n",
      "X_test = X_combined[~mask]\n",
      "\n",
      "Y_train = Y_combined[mask]\n",
      "Y_test = Y_combined[~mask]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "reload(cv)\n",
      "cv.find_best_model(X, Y, sklearn.linear_model.LogisticRegression, lr_parameter_grids)\n",
      "#cv.find_best_model(X_train, Y_train, sklearn.ensemble.RandomForestClassifier, [\n",
      "#    {'n_estimators' : [10, 20, 40, 80, 160], 'max_depth' : [None, 10, 20, 30]}]) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Param_grid #1/1 {'penalty': ['l1', 'l2'], 'C': [1e-06, 1e-05, 0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'fit_intercept': [True, False]}\n",
        "-- LogisticRegression(C=1e-06, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l1', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.5000\n",
        "\n",
        "-- LogisticRegression(C=1e-06, class_weight=None, dual=False,\n",
        "          fit_intercept=False, intercept_scaling=1, penalty='l1',\n",
        "          random_state=None, tol=0.0001)\n",
        "-- AUC: 0.5000\n",
        "\n",
        "-- LogisticRegression(C=1e-05, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l1', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.5000\n",
        "\n",
        "-- LogisticRegression(C=1e-05, class_weight=None, dual=False,\n",
        "          fit_intercept=False, intercept_scaling=1, penalty='l1',\n",
        "          random_state=None, tol=0.0001)\n",
        "-- AUC: 0.5000\n",
        "\n",
        "-- LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
        "          fit_intercept=True, intercept_scaling=1, penalty='l1',\n",
        "          random_state=None, tol=0.0001)\n",
        "-- AUC: 0.5000\n",
        "\n",
        "-- LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
        "          fit_intercept=False, intercept_scaling=1, penalty='l1',\n",
        "          random_state=None, tol=0.0001)\n",
        "-- AUC: 0.5000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "-- LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l1', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.5000\n",
        "\n",
        "-- LogisticRegression(C=0.001, class_weight=None, dual=False,\n",
        "          fit_intercept=False, intercept_scaling=1, penalty='l1',\n",
        "          random_state=None, tol=0.0001)\n",
        "-- AUC: 0.5000\n",
        "\n",
        "-- LogisticRegression(C=0.005, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l1', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.5000\n",
        "\n",
        "-- LogisticRegression(C=0.005, class_weight=None, dual=False,\n",
        "          fit_intercept=False, intercept_scaling=1, penalty='l1',\n",
        "          random_state=None, tol=0.0001)\n",
        "-- AUC: 0.5000\n",
        "\n",
        "-- LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l1', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.6799\n",
        "\n",
        "-- LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=False,\n",
        "          intercept_scaling=1, penalty='l1', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.6799"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "-- LogisticRegression(C=0.05, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l1', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.7183\n",
        "\n",
        "-- LogisticRegression(C=0.05, class_weight=None, dual=False, fit_intercept=False,\n",
        "          intercept_scaling=1, penalty='l1', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.7188\n",
        "\n",
        "-- LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l1', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.7156\n",
        "\n",
        "-- LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=False,\n",
        "          intercept_scaling=1, penalty='l1', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.7165\n",
        "\n",
        "-- LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l1', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.7007"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "-- LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=False,\n",
        "          intercept_scaling=1, penalty='l1', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.7008\n",
        "\n",
        "-- LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l1', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.6969"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "-- LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=False,\n",
        "          intercept_scaling=1, penalty='l1', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.6981\n",
        "\n",
        "-- LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l1', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.6943"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "-- LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=False,\n",
        "          intercept_scaling=1, penalty='l1', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.6955"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "-- LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l1', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.6938"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "-- LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=False,\n",
        "          intercept_scaling=1, penalty='l1', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.6945"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "-- LogisticRegression(C=1e-06, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.7174\n",
        "\n",
        "-- LogisticRegression(C=1e-06, class_weight=None, dual=False,\n",
        "          fit_intercept=False, intercept_scaling=1, penalty='l2',\n",
        "          random_state=None, tol=0.0001)\n",
        "-- AUC: 0.7174\n",
        "\n",
        "-- LogisticRegression(C=1e-05, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.7173\n",
        "\n",
        "-- LogisticRegression(C=1e-05, class_weight=None, dual=False,\n",
        "          fit_intercept=False, intercept_scaling=1, penalty='l2',\n",
        "          random_state=None, tol=0.0001)\n",
        "-- AUC: 0.7173\n",
        "\n",
        "-- LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
        "          fit_intercept=True, intercept_scaling=1, penalty='l2',\n",
        "          random_state=None, tol=0.0001)\n",
        "-- AUC: 0.7172\n",
        "\n",
        "-- LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
        "          fit_intercept=False, intercept_scaling=1, penalty='l2',\n",
        "          random_state=None, tol=0.0001)\n",
        "-- AUC: 0.7172"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "-- LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.7157\n",
        "\n",
        "-- LogisticRegression(C=0.001, class_weight=None, dual=False,\n",
        "          fit_intercept=False, intercept_scaling=1, penalty='l2',\n",
        "          random_state=None, tol=0.0001)\n",
        "-- AUC: 0.7157\n",
        "\n",
        "-- LogisticRegression(C=0.005, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.7104\n",
        "\n",
        "-- LogisticRegression(C=0.005, class_weight=None, dual=False,\n",
        "          fit_intercept=False, intercept_scaling=1, penalty='l2',\n",
        "          random_state=None, tol=0.0001)\n",
        "-- AUC: 0.7105\n",
        "\n",
        "-- LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- AUC: 0.7071\n",
        "\n",
        "-- LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=False,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.7074\n",
        "\n",
        "-- LogisticRegression(C=0.05, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.7004\n",
        "\n",
        "-- LogisticRegression(C=0.05, class_weight=None, dual=False, fit_intercept=False,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.7010"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "-- LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.6985\n",
        "\n",
        "-- LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=False,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.6993\n",
        "\n",
        "-- LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.6960\n",
        "\n",
        "-- LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=False,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.6967"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "-- LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.6956\n",
        "\n",
        "-- LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=False,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.6965\n",
        "\n",
        "-- LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.6935\n",
        "\n",
        "-- LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=False,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.6946"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "-- LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.6933\n",
        "\n",
        "-- LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=False,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "-- AUC: 0.6942\n",
        "\n",
        "== Best Model: LogisticRegression(C=0.05, class_weight=None, dual=False, fit_intercept=False,\n",
        "          intercept_scaling=1, penalty='l1', random_state=None, tol=0.0001), AUC = 0.7188\n",
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 136,
       "text": [
        "(<helpers.Normalizer at 0x1103b1550>,\n",
        " {'C': 0.05, 'fit_intercept': False, 'penalty': 'l1'},\n",
        " 0.71877089210419876)"
       ]
      }
     ],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best_model, params, auc = _"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 137
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best_model.fit(X_train, Y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y_pred = best_model.predict_proba(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 142
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv.roc_auc_score("
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 141,
       "text": [
        "(702, 688)"
       ]
      }
     ],
     "prompt_number": 141
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "params"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 101,
       "text": [
        "{'C': 0.05, 'fit_intercept': False, 'penalty': 'l1'}"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best_model.model.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 103,
       "text": [
        "array([[ 0.        ,  0.        ,  0.        , -0.26486051, -0.08681656,\n",
        "         0.        , -0.22612772,  0.        ,  0.03915365,  0.17093746,\n",
        "         0.        ,  0.        ,  0.01570541,  0.01071426, -0.08967502,\n",
        "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
        "         0.        ,  0.        ]])"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[datasets['features'][i] for (i, x) in enumerate(best_model.model.coef_.ravel()) if x > 0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 110,
       "text": [
        "['Max_Dose', 'Marginal_Dose', 'Surgery', 'Location_frontal']"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}